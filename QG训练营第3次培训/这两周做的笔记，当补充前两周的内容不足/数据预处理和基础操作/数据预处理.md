<center>数据预处理</center>

现在有点明白为什么数据预处理是通常占据整个工作量的大头了。脑壳疼。

# 数据1

数据给出了用户的特征，要我们训练分类模型，用来判断用户是否违约。要用的算法分别是knn算法和逻辑回归算法。

## 数据预处理

### 泛泛的数据预处理

对于离散性的特征，要做独热编码

对于连续性的特征，要做归一化和标准化。

此外有些缺失值和异常值的处理也要关注，你比如说有些用户的数据十分的奇怪，像387号用户或者509号用户，从$x_1$到$x_{78}$的数据全都是-999,十分的引人注意。猜想-999是异常值。也把它们给清除了叭。但是residentAddr的-999就不能删除了，要替换为平均值。



此外还可能有一些数据需要填充。

然后还要划分训练集，验证集测试集balabala的。

烦死个人。

### 逻辑回归的特征选择

肯定是要使用多项式回归的，但是上来就是一系列很麻烦的问题，第一个就是特征怎么选择，怎么判定这个特征是有用的还是没用的。第二个就是筛选过有用的特征之后，该怎么选定特定的特征值的次方数。

一些应该没有用的特征：

bankCard,-999作为异常值比正常的数据还要多，特征残缺太过严重，有相似问题的特征还有hightestEdv，直接删掉问题应该不大。此外我再“相信”certId是与结果无关的，~~那就又可以删掉一个特征了嘻嘻嘻。~~

此外还有些数据集像$x_{77}$和$x_{78}$这个样子的特征，除了异常值-999以外其他都是0，那肯定也是没有什么用的,与之形成对比的有诸如$x_{22}$这样几乎全是1的特征。真的是伤脑筋，$x_0$到$x_{78}$的特征优先不考虑使用好了。还有那个isNew的特征分布也是十分的不好，删掉删掉。

### 删除特征







### 独热编码





### 归一化











## 逻辑回归